import numpy as np
import scipy.sparse as sp
import torch
from torch.utils.data import Dataset, DataLoader

def convert_dataloader(ds, batch_size, shuffle, num_workers=4):  
    return DataLoader(
        ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)

class BasicDataset(Dataset):
    def __init__(self, samples):
        '''
        convert array-like <u, i, j> / <u, i, r> / <target_i, context_i, label>

        Parameters
        ----------
        samples : np.array
            samples generated by sampler
        '''        
        super(BasicDataset, self).__init__()
        self.data = samples

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        return self.data[index][0], self.data[index][1], self.data[index][2]

class CandidatesDataset(Dataset):
    def __init__(self, ucands):
        super(CandidatesDataset, self).__init__()
        self.data = ucands

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        return torch.tensor(self.data[index][0]), torch.tensor(self.data[index][1])

class UAEData(Dataset):
    def __init__(self, user_num, item_num, train_set, test_set):
        """
        user-level Dataset formatter adapted AutoEncoder-like algorithms
        Parameters
        ----------
        user_num : int, the number of users
        item_num : int, the number of items
        train_set : pd.DataFrame, training set
        test_set : pd.DataFrame, test set
        """
        super(UAEData, self).__init__()
        self.user_num = user_num
        self.item_num = item_num

        self.R = sp.dok_matrix((user_num, item_num), dtype=np.float32)  # true label
        self.mask_R = sp.dok_matrix((user_num, item_num), dtype=np.float32) # only concern interaction known
        self.user_idx = np.array(range(user_num))

        for _, row in train_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[user, item] = 1.
            self.mask_R[user, item] = 1.

        for _, row in test_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[user, item] = 1.

    def __len__(self):
        return self.user_num

    def __getitem__(self, idx):
        u = self.user_idx[idx]
        ur = self.R[idx].A.squeeze()
        mask_ur = self.mask_R[idx].A.squeeze()

        return u, ur, mask_ur


class IAEData(Dataset):
    def __init__(self, user_num, item_num, train_set, test_set):
        """
        item-level Dataset formatter adapted AutoEncoder-like algorithms
        Parameters
        ----------
        user_num : int, the number of users
        item_num : int, the number of items
        train_set : pd.DataFrame, training set
        test_set : pd.DataFrame, test set
        """
        super(IAEData, self).__init__()
        self.user_num = user_num
        self.item_num = item_num
        
        self.R = sp.dok_matrix((item_num, user_num), dtype=np.float32)  # true label
        self.mask_R = sp.dok_matrix((item_num, user_num), dtype=np.float32) # only concern interaction known
        self.item_idx = np.array(range(item_num))

        for _, row in train_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[item, user] = 1.
            self.mask_R[item, user] = 1.

        for _, row in test_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[item, user] = 1.

    def __len__(self):
        return self.item_num

    def __getitem__(self, idx):
        i = self.item_idx[idx]
        ir = self.R[idx].A.squeeze()
        mask_ir = self.mask_R[idx].A.squeeze()

        return i, ir, mask_ir
